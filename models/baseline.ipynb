{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3602140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Conv1D, InputLayer, Masking, MaxPooling1D, GlobalAveragePooling1D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d76481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self, train):\n",
    "        self.inputs, self.ys = self.get_train(train)\n",
    "        \n",
    "        self.model = self.build_model()\n",
    "        \n",
    "        self.callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath='models.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                save_best_only=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "    def get_train(self, train):\n",
    "        inputs = []\n",
    "        ys = []\n",
    "        \n",
    "        for t in train:\n",
    "            sig = t['sig']\n",
    "            len_sig = t['sig_len']\n",
    "            fs = t['fs']\n",
    "            for i in range(int(len_sig/fs)):\n",
    "                # input range: sig[i:i+fs]\n",
    "                if i+fs <= len(sig):\n",
    "                    input_sig = sig[i:i+fs]\n",
    "                else:\n",
    "                    input_sig = sig[i:]\n",
    "                inputs.append(input_sig)\n",
    "                \n",
    "                if t['class_true'] == 0:\n",
    "                    y = 0\n",
    "                elif t['class_true'] == 1:\n",
    "                    y = 1\n",
    "                else:\n",
    "                    y = 0\n",
    "                    for j in range(len(t['af_start_scripts'])):\n",
    "                        if i in range(t['af_start_scripts'][j], t['af_end_scripts'][j] + 1):\n",
    "                            y = 1\n",
    "                            break\n",
    "                    \n",
    "                ys.append(y)\n",
    "                \n",
    "        inputs = np.array(inputs)\n",
    "        ys = np.array(ys)\n",
    "        \n",
    "        return inputs, ys\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Masking(mask_value=0, input_shape=(200, 2)))\n",
    "        model.add(Conv1D(16, 12, activation='relu'))\n",
    "        model.add(Conv1D(16, 12, activation='relu'))\n",
    "        model.add(MaxPooling1D(3))\n",
    "        model.add(Conv1D(32, 12, activation='relu'))\n",
    "        model.add(Conv1D(32, 12, activation='relu'))\n",
    "        model.add(GlobalAveragePooling1D())\n",
    "#         model.add(Dropout(0.5))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(3, activation='softmax')) # af start, af end, non af\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    def fit(self):\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        self.model.summary()\n",
    "                \n",
    "        self.model.fit(self.inputs,\n",
    "                       to_categorical(self.ys, 3),\n",
    "                       batch_size = 500,\n",
    "                       epochs = 5,\n",
    "                       verbose = 1,\n",
    "                       validation_split = 0.2,\n",
    "                       callbacks = self.callbacks)\n",
    "        \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c503272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PATH = '../data/train.pkl'\n",
    "TEST_DATA_PATH = '../data/test.pkl'\n",
    "\n",
    "# load data\n",
    "with open(TRAINING_DATA_PATH, 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open(TEST_DATA_PATH, 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be32890f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['record_name', 'sig', 'sig_len', 'fs', 'beat_loc', 'af_start_scripts', 'af_end_scripts', 'class_true'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb226d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, t in enumerate(train):\n",
    "#     if t['class_true'] == 2:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "815b92ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 20:14:27.121476: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-20 20:14:27.121976: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 200, 2)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 189, 16)           400       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 178, 16)           3088      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 59, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 48, 32)            6176      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 37, 32)            12320     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 23,619\n",
      "Trainable params: 23,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 20:14:29.205567: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2151/2151 [==============================] - 140s 65ms/step - loss: 0.3409 - accuracy: 0.8565 - val_loss: 0.3580 - val_accuracy: 0.8269\n",
      "Epoch 2/5\n",
      "2151/2151 [==============================] - 137s 64ms/step - loss: 0.2636 - accuracy: 0.8732 - val_loss: 0.2511 - val_accuracy: 0.8983\n",
      "Epoch 3/5\n",
      "2151/2151 [==============================] - 136s 63ms/step - loss: 0.1343 - accuracy: 0.9452 - val_loss: 0.2542 - val_accuracy: 0.9138\n",
      "Epoch 4/5\n",
      "2151/2151 [==============================] - 136s 63ms/step - loss: 0.0930 - accuracy: 0.9616 - val_loss: 0.2551 - val_accuracy: 0.9141\n",
      "Epoch 5/5\n",
      "2151/2151 [==============================] - 137s 64ms/step - loss: 0.0762 - accuracy: 0.9680 - val_loss: 0.3205 - val_accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(train)\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f537c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (deep_learning)",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
