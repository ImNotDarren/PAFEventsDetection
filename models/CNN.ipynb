{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1e00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import sample\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, model_from_json\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Conv1D, InputLayer, Masking, MaxPooling1D, GlobalAveragePooling1D, Dropout\n",
    "from biosppy.signals.tools import filter_signal\n",
    "from biosppy.signals import ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3749eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_model()\n",
    "        self.Xs = []\n",
    "        self.ys = []\n",
    "        self.callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath='models.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                save_best_only=True\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # build cnn\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Masking(mask_value=0, input_shape=(1300, 2)))\n",
    "        model.add(Conv1D(16, 13, activation='relu'))\n",
    "        model.add(Conv1D(16, 13, activation='relu'))\n",
    "        model.add(MaxPooling1D(3))\n",
    "        model.add(Conv1D(32, 13, activation='relu'))\n",
    "        model.add(Conv1D(32, 13, activation='relu'))\n",
    "        model.add(GlobalAveragePooling1D())\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(2, activation='softmax')) # af, non-af\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def get_train(self, train):\n",
    "        # get X and y\n",
    "        # scan the first five heartbeats to predict the fifth\n",
    "        for i, t in enumerate(train):\n",
    "            print(str(i+1) + '/' + str(len(train)), end='\\r')\n",
    "            rpeaks = t['rpeaks']\n",
    "            # from the seventh peak\n",
    "            for p in range(6, len(rpeaks)):\n",
    "                start = rpeaks[p-6]\n",
    "                end = rpeaks[p]\n",
    "                if end - start > 1300:\n",
    "                    end = start + 1299\n",
    "                sig = t['sig_filtered'][start:end+1]\n",
    "                # classification on p-1 location\n",
    "                if t['class_true'] == 1:\n",
    "                    y = 1\n",
    "                elif t['class_true'] == 2:\n",
    "                    # if p-1 is between an af start and end point, y = 1\n",
    "                    for j in range(len(t['af_start'])):\n",
    "                        if t['rpeaks'][p-1] in range(t['af_start'][j], t['af_end'][j] + 1):\n",
    "                            y = 1\n",
    "                            break\n",
    "                else:\n",
    "                    y = 0\n",
    "                        \n",
    "                self.Xs.append(sig)\n",
    "                self.ys.append(y)\n",
    "                \n",
    "#         self.Xs = np.array(self.Xs)\n",
    "            \n",
    "        \n",
    "    def filter_signals(self, sig, fs):\n",
    "        sig_filtered = [filter_signal(sig[:,0],\n",
    "                        ftype='FIR',\n",
    "                        band='bandpass',\n",
    "                        order=50,\n",
    "                        frequency=[0.5,45],\n",
    "                        sampling_rate=fs)[0],\n",
    "                        filter_signal(sig[:,1],\n",
    "                        ftype='FIR',\n",
    "                        band='bandpass',\n",
    "                        order=50,\n",
    "                        frequency=[0.5,45],\n",
    "                        sampling_rate=fs)[0]\n",
    "                        ]\n",
    "        return sig_filtered\n",
    "    \n",
    "    def get_rpeaks(self, sig_filtered, fs):\n",
    "        rpeaks = ecg.christov_segmenter(sig_filtered[0], fs)[0]\n",
    "        return rpeaks\n",
    "        \n",
    "    # only for test data, training data has already been preprocessed\n",
    "    def preprocessing(self, test):\n",
    "        \n",
    "        for i in range(len(test)):\n",
    "            print(str(i+1) + '/' + str(len(test)), end='\\r')\n",
    "            # filter signals and get rpeaks\n",
    "            sig = self.filter_signals(test[i]['sig'], test[i]['fs'])\n",
    "            rpeaks = self.get_rpeaks(sig, test[i]['fs'])\n",
    "            sig = np.transpose(sig)\n",
    "            \n",
    "            test[i]['sig_filtered'] = sig\n",
    "            test[i]['rpeaks'] = rpeaks\n",
    "        \n",
    "        return test\n",
    "    \n",
    "    def fit(self, train):\n",
    "        \n",
    "        self.get_train(train)\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        self.model.summary()\n",
    "        \n",
    "        self.model.fit(self.Xs,\n",
    "                       to_categorical(self.ys, 2),\n",
    "                       batch_size = 200,\n",
    "                       epochs = 10,\n",
    "                       verbose = 1,\n",
    "                       validation_split = 0.2,\n",
    "                       callbacks = self.callbacks)\n",
    "        \n",
    "    def score(self, test):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf81e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING_DATA_PATH = '../data/train_preprocessed.pkl'\n",
    "# TEST_DATA_PATH = '../data/test.pkl'\n",
    "\n",
    "# # load data\n",
    "# with open(TRAINING_DATA_PATH, 'rb') as file:\n",
    "#     train = pickle.load(file)\n",
    "\n",
    "# with open(TEST_DATA_PATH, 'rb') as file:\n",
    "#     test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005b2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PATH = '../data/train_sampled_2.json'\n",
    "\n",
    "with open(TRAINING_DATA_PATH, 'r') as file:\n",
    "    train = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1746e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further process training data\n",
    "# train_saved = train\n",
    "# for i in range(len(train)):\n",
    "#     print(str(i+1) + '/' + str(len(train)), end='\\r')\n",
    "#     train[i]['af_start'] = [train[i]['beat_loc'][x] for x in train[i]['af_start_scripts']]\n",
    "#     train[i]['af_end'] = [train[i]['beat_loc'][x] for x in train[i]['af_end_scripts']]\n",
    "#     del train[i]['af_start_scripts']\n",
    "#     del train[i]['af_end_scripts']\n",
    "#     del train[i]['beat_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f1db3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['record_name', 'fs', 'sig_filtered', 'rpeaks', 'class_true', 'af_start', 'af_end'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb1c12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 23:13:51.679009: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-02 23:13:51.681462: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 1300, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1288, 16)          432       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1276, 16)          3344      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 425, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 413, 32)           6688      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 401, 32)           13344     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 25,426\n",
      "Trainable params: 25,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cnn.Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eab694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (deep_learning)",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
