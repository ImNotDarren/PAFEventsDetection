{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78fad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84569848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(sample_path):\n",
    "    record = wfdb.rdrecord(sample_path)\n",
    "    fields = record.__dict__\n",
    "    sig = fields['p_signal']\n",
    "    length = fields['sig_len']\n",
    "    fs = fields['fs']\n",
    "    comments = fields['comments'][0]\n",
    "    if comments == 'paroxysmal atrial fibrillation':\n",
    "        result = 'AFp'\n",
    "    elif comments == 'persistent atrial fibrillation':\n",
    "        result = 'AFf'\n",
    "    else:\n",
    "        result = 'N'\n",
    "        \n",
    "    record_name = fields['record_name']\n",
    "\n",
    "    return record_name, sig, length, fs, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15529b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = ['../../ECG Recordings/Training_set_I', '../../ECG Recordings/Training_set_II']\n",
    "training_data_I = os.listdir(DATA_PATH[0])\n",
    "training_data_II = os.listdir(DATA_PATH[1])\n",
    "\n",
    "samples = [[], []]\n",
    "for data in training_data_I:\n",
    "    samples[0].append(data[:-4])\n",
    "for data in training_data_II:\n",
    "    samples[1].append(data[:-4])\n",
    "samples = [list(set(samples[0])), list(set(samples[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb7ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for s in samples[0]:\n",
    "    record_name, sig, length, fs, result = load_training_data(DATA_PATH[0] + '/' + s)\n",
    "    data = {\"record_name\": record_name, \"sig\": sig, \"sig_len\": length, \"fs\": fs, \"result\": result}\n",
    "    training_data.append(data)\n",
    "    \n",
    "for s in samples[1]:\n",
    "    record_name, sig, length, fs, result = load_training_data(DATA_PATH[1] + '/' + s)\n",
    "    data = {\"record_name\": record_name, \"sig\": sig, \"sig_len\": length, \"fs\": fs, \"result\": result}\n",
    "    training_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c5b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.pkl', 'wb') as file:\n",
    "    pickle.dump(training_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd8c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (deep_learning)",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
