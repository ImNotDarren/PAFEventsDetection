{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78fad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84569848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(sample_path):\n",
    "    record = wfdb.rdrecord(sample_path)\n",
    "    ann_ref = wfdb.rdann(sample_path, 'atr')\n",
    "    fields = record.__dict__\n",
    "    sig = fields['p_signal']\n",
    "    length = fields['sig_len']\n",
    "    fs = fields['fs']\n",
    "    comments = fields['comments'][0]\n",
    "    if comments == 'paroxysmal atrial fibrillation':\n",
    "        class_true = 2\n",
    "    elif comments == 'persistent atrial fibrillation':\n",
    "        class_true = 1\n",
    "    else:\n",
    "        class_true = 0\n",
    "        \n",
    "    record_name = fields['record_name']\n",
    "    \n",
    "    # y\n",
    "    \n",
    "    beat_loc = np.array(ann_ref.sample)\n",
    "    ann_note = np.array(ann_ref.aux_note)\n",
    "    af_start_scripts = np.where((ann_note=='(AFIB') | \\\n",
    "                                (ann_note=='(AFL'))[0]\n",
    "    af_end_scripts = np.where(ann_note=='(N')[0]\n",
    "\n",
    "    return record_name, sig, length, fs, beat_loc, af_start_scripts, af_end_scripts, class_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15529b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = ['../../ECG Recordings/Training_set_I', '../../ECG Recordings/Training_set_II']\n",
    "training_data_I = os.listdir(DATA_PATH[0])\n",
    "training_data_II = os.listdir(DATA_PATH[1])\n",
    "\n",
    "samples = [[], []]\n",
    "for data in training_data_I:\n",
    "    samples[0].append(data[:-4])\n",
    "for data in training_data_II:\n",
    "    samples[1].append(data[:-4])\n",
    "samples = [list(set(samples[0])), list(set(samples[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb7ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for s in samples[0]:\n",
    "    record_name, sig, length, fs, beat_loc, \\\n",
    "        af_start_scripts, af_end_scripts, class_true = \\\n",
    "            load_training_data(DATA_PATH[0] + '/' + s)\n",
    "    data = {\"record_name\": record_name, \"sig\": sig, \"sig_len\": length, \"fs\": fs, \"beat_loc\": beat_loc, \"af_start_scripts\": af_start_scripts, \"af_end_scripts\": af_end_scripts, \"class_true\": class_true}\n",
    "    training_data.append(data)\n",
    "    \n",
    "for s in samples[1]:\n",
    "    record_name, sig, length, fs, beat_loc, \\\n",
    "        af_start_scripts, af_end_scripts, class_true = \\\n",
    "            load_training_data(DATA_PATH[1] + '/' + s)\n",
    "    data = {\"record_name\": record_name, \"sig\": sig, \"sig_len\": length, \"fs\": fs, \"beat_loc\": beat_loc, \"af_start_scripts\": af_start_scripts, \"af_end_scripts\": af_end_scripts, \"class_true\": class_true}\n",
    "    training_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c5b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.pkl', 'wb') as file:\n",
    "    pickle.dump(training_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd8c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (deep_learning)",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
